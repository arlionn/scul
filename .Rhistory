#custom_colors <- c("#F98400", "#00A08A", "#5BBCD6")
CustomColors <- c("black", "white", "red")
# Loop through all the possible cross validations
for(j in 1:MaxCrossValidations)
{
# Identify the possible set of test data: From one after the training data ends until the end of the pre-treatment period.
RangeOfFullSetOfTestData <- (NumberInitialTimePeriods+j):PrePeriodLength #7:20
# Identify the actual set of test data: From one after the training data ends until the end of test data
RangeOfjthTestData <- (NumberInitialTimePeriods+j):(NumberInitialTimePeriods+j+TrainingPostPeriodLength-1)
# Identify the actual set of data left out: From one after the test data ends until the end of pre-treatment data
RangeOfLeftoutData <- (NumberInitialTimePeriods+j+TrainingPostPeriodLength):PrePeriodLength
#  Identify the training data. From the first one until adding (J-1).
RangeOfTrainingData <- 1:(NumberInitialTimePeriods-1+j)
# Put arrows through the data points to represent time
arrows(0,1-j/MaxCrossValidations,PrePeriodLength+1,1-j/MaxCrossValidations,0.05)
# Add squares to all of the training data
points(RangeOfTrainingData,rep(1-j/MaxCrossValidations,length(RangeOfTrainingData)),pch=15,col=CustomColors[1])
# Add X's to the unused data
if(length(RangeOfFullSetOfTestData) > TrainingPostPeriodLength)
points(RangeOfLeftoutData, rep(1-j/MaxCrossValidations,length(RangeOfLeftoutData)), pch=4, col=CustomColors[3])
# Add circles to the test data
if(length(RangeOfFullSetOfTestData) >= TrainingPostPeriodLength)
points(RangeOfjthTestData,rep(1-j/MaxCrossValidations,length(RangeOfjthTestData)), pch=21, col="black",bg=CustomColors[2])
}
# Add informative text and bracket
## label what is training data
brackets(1, .9 , NumberInitialTimePeriods, .9, h=.05)
text((NumberInitialTimePeriods+1)/2,1.15,"Training data\n for 1st CV")
## label what is test data
brackets((NumberInitialTimePeriods+1), .9 , (NumberInitialTimePeriods+TrainingPostPeriodLength), .9, h=.05)
text((NumberInitialTimePeriods+TrainingPostPeriodLength)-((TrainingPostPeriodLength-1)/2),1.15,"Test data\n for 1st CV")
## label what is left-out data
brackets(NumberInitialTimePeriods+TrainingPostPeriodLength+1, .9 , PrePeriodLength, .9, h=.05)
text((PrePeriodLength-(PrePeriodLength-NumberInitialTimePeriods-TrainingPostPeriodLength)/2),1.15,"Left-out data\n for 1st CV")
## Add a legend so it will be clear in black and white
legend(
x="bottom",
legend=c("Training", "Testing","Left-out"),
bg=CustomColors,
col=c(CustomColors[1], "black", CustomColors[3]),
lwd=1,
lty=c(0,0),
pch=c(15,21,4),
bty="n",
horiz = TRUE,
x.intersp=.5,
y.intersp= .25 ,
text.width=c(2.5,2.5,2.5)
)
# Add custom x-axis labels to indicate time until treatment
text(PrePeriodLength/2,-.35,"Time period relative to treatment", cex=1)
CustomXLables <-seq((-PrePeriodLength),0, by=1)
for (z in seq(from = 1, to = PrePeriodLength + 1, by=5)) {
text(z, -.15, CustomXLables[z], cex=1)
}
# Add custom y-axis labels to indicate CV run number
text(-3.5,1,bquote(underline("CV Run")), cex=1)
for (z in seq(from = 0, to = 1-1/MaxCrossValidations, by = (1/MaxCrossValidations))) {
TempLabel = MaxCrossValidations - z*MaxCrossValidations
text(-3.5,z,TempLabel, cex=1)
}
# Add title
#title(main = "Example of rolling origin cross-validation procedure",line = -.8)
text(-3.75, 1.5, "Example of rolling-origin k-fold cross-validation",cex=1.5,adj=0)
# Save graph
FullPlotPath<-paste0(SCUL.input$OutputFilePath,"visual_illustration_of_cross_validation.pdf")
dev.copy(pdf,FullPlotPath, width=12, height=8)
dev.off()
SCUL.output <- SCUL()
PlotActualvSCUL()
# Calculate pre-treatment sd
PreTreatmentSD <- sd(unlist(SCUL.output$y.actual[1:(SCUL.input$TreatmentBeginsAt-1),]))
# Store Cohen's D in each period for cross-validated lambda
StandardizedDiff <- abs(SCUL.output$y.actual-SCUL.output$y.scul)/PreTreatmentSD
names(StandardizedDiff) <- c("scul.cv")
# Store Cohen's D in each period for max lambda
StandardizedDiff$naive_prediction_1 <- abs(data_to_plot_scul_vary_lambda$naive_prediction_1 - data_to_plot_scul_vary_lambda$actual_y)/PreTreatmentSD
StandardizedDiff$naive_prediction_2 <- abs(data_to_plot_scul_vary_lambda$naive_prediction_2 - data_to_plot_scul_vary_lambda$actual_y)/PreTreatmentSD
StandardizedDiff$naive_prediction_3 <- abs(data_to_plot_scul_vary_lambda$naive_prediction_3 - data_to_plot_scul_vary_lambda$actual_y)/PreTreatmentSD
StandardizedDiff$naive_prediction_4 <- abs(data_to_plot_scul_vary_lambda$naive_prediction_4 - data_to_plot_scul_vary_lambda$actual_y)/PreTreatmentSD
# Show Cohen's D for each of these
CohensD <- data.frame(colMeans(StandardizedDiff[1:(TreatmentBeginsAt-1),]))
# Calculate treatment effect for each of these
TreatmentEffect <- SCUL.output$y.actual-SCUL.output$y.scul
names(TreatmentEffect) <- c("scul.cv")
TreatmentEffect$naive_prediction_1 <-
data_to_plot_scul_vary_lambda$actual_y -
data_to_plot_scul_vary_lambda$naive_prediction_1
TreatmentEffect$naive_prediction_2 <-
data_to_plot_scul_vary_lambda$actual_y -
data_to_plot_scul_vary_lambda$naive_prediction_2
TreatmentEffect$naive_prediction_3 <-
data_to_plot_scul_vary_lambda$actual_y-
data_to_plot_scul_vary_lambda$naive_prediction_3
TreatmentEffect$naive_prediction_4 <-
data_to_plot_scul_vary_lambda$actual_y -
data_to_plot_scul_vary_lambda$naive_prediction_4
AvgTreatmentEffect <- data.frame(colMeans(TreatmentEffect[TreatmentBeginsAt:nrow(StandardizedDiff),]))
# For target variable
Results.y.CohensD <- SCUL.output$CohensD
Results.y.StandardizedDiff <- (SCUL.output$y.actual-SCUL.output$y.scul)/sd(unlist(SCUL.output$y.actual[1:(SCUL.input$TreatmentBeginsAt-1),]))
Results.y <- SCUL.output$y.scul
table_for_hux <- cbind(
(CohensD),
(AvgTreatmentEffect)
)
names(table_for_hux) <- c("CohensD", "ATE")
table_for_hux$name <- c("Cross-validation for determining penalty", "Naive guess 1:\n Max penalty (remove all donors)", "Naive guess 2:\n Random penalty", "Naive guess 3:\n Random penalty", "Naive guess 4:\n No penalty (include all donors)")
table_for_hux$value <- c(SCUL.output$CrossValidatedLambda, first_guess_lasso$lambda[1], first_guess_lasso$lambda[round(length(first_guess_lasso$lambda)/10)], first_guess_lasso$lambda[round(length(first_guess_lasso$lambda)/5)], 0)
table_for_hux <- table_for_hux[c(3, 4, 1,2)]
kable(table_for_hux, col.names = c("Method","Penalty parameter", "Cohens D (pre-period fit)", "ATE estimate"), digits = 2, row.names = FALSE) %>%
kable_styling(bootstrap_options = "striped", full_width = F) %>%
column_spec(1, width = "5cm") %>%
column_spec(2:4, width = "2cm")  %>%
pack_rows("SCUL procedure using:", 1, 1) %>%
pack_rows("SCUL using naive guesses for penalty", 2, 5)
PlotShareTable()
SCUL.inference <- CreatePlaceboDistribution()
###############################################################################################
# Make Smoke Plot
# Trim placebos with poor pre-treatment fit
placebo.distribution.trim <- data.frame(SCUL.inference$y.placebo.StandardizedDifference.Full)[,data.frame(SCUL.inference$y.placebo.CohensD) <=.25 ]
colMax <- function(data) sapply(data, max, na.rm = TRUE)
# reshape the placebo data to be in long form
data_to_plot_wide_y <- cbind( SCUL.input$time, Results.y.StandardizedDiff)
names(data_to_plot_wide_y) <- c("time", "std_diff")
data_to_plot_wide <- cbind( SCUL.input$time, placebo.distribution.trim)
names(data_to_plot_wide)[1] <- c("time")
data_to_plot_long <- pivot_longer(data = data_to_plot_wide,
cols = starts_with("X"),
names_to = "group",
names_prefix = "X",
values_to = "std_diff",
values_drop_na = TRUE
)
# create smoke plot
smoke_plot <- ggplot(data = data_to_plot_long, aes(x = time, y = std_diff)) +
geom_line(aes(group = group), alpha = .5, size = 1) +
theme_classic() +
geom_line(data = data_to_plot_wide_y, aes(x = time, y = std_diff), alpha = 1, size = 2., color = "black") +
geom_line(data = data_to_plot_wide_y, aes(x = time, y = std_diff), alpha = 1, size = 1.75, color = "#4dac26") +
geom_vline(
xintercept = SCUL.input$time[TreatmentBeginsAt,1],
linetype = "dashed",
size = 1,
color = "grey37"
) +
labs(
title = "Standardized difference for CA cigarette sales compared to standardized\n difference for each placebo donor product",
x = "Time",
y = "Difference between actual data and scul prediction\n in pre-treatment standard deviations for each product"
) +
theme(
axis.text = element_text(size = 18),
axis.title.y = element_text(size = 12),
axis.title.x = element_text(size = 18),
title = element_text(size = 12),
legend.position = "none"
)
# Save graph
SmokePlotPath<-paste0(SCUL.input$OutputFilePath,"smoke_plot.png")
ggsave(SmokePlotPath,
plot = smoke_plot,
width = 8,
height = 5,
dpi = 300,
units = "in")
# Display graph
smoke_plot
# Plot null distribution with no restriction on pre-period fit
NullDist.Full <- PlotNullDistribution(
CohensD = 999,
StartTime = TreatmentBeginsAt,
EndTime = nrow(SCUL.output$y.actual),
height = 2,
AdjustmentParm = 1,
BandwidthParm = .25,
title_label = "Placebo distribution compared\n to ATE estimate in\n pre-period standard deviations",
y_label  = " ",
x_label  =  "",
subtitle_label  =  "No Cohen's D restriction",
rejection_label  =  ""
) +
geom_vline(
xintercept = mean(Results.y.StandardizedDiff[TreatmentBeginsAt:nrow(Results.y.StandardizedDiff),]),
linetype = "dashed",
size = 1,
color = "red")
# Plot null distribution 0.25 cohen's D restriction on pre-period fit
NullDist.25 <- PlotNullDistribution(
CohensD = 0.25,
StartTime = TreatmentBeginsAt,
EndTime = nrow(SCUL.output$y.actual),
height = 2,
AdjustmentParm = 1,
BandwidthParm = .25,
y_label  = "",
x_label  =  "Distribution of standardized difference\n for placebo donor pool",
subtitle_label  =  "0.25 Cohen's D restriction",
rejection_label  =  "",
title_label = " ",
) +
geom_vline(
xintercept = mean(Results.y.StandardizedDiff[TreatmentBeginsAt:nrow(Results.y.StandardizedDiff),]),
linetype = "dashed",
size = 1,
color = "red")
# Plot n
# Combine the three plots
combined_plot <- plot_grid(
NullDist.Full,NullDist.25,
ncol = 1)
# Save the plot
FilePath <- paste0(SCUL.input$OutputFilePath,"mde_graph.pdf")
ggsave(FilePath,
plot = combined_plot,
width = 4,
height = 8,
units = "in")
# Display the plot
combined_plot
#########################################################################################################
# Calculate an average post-treatment p-value
PValue(
CohensD = 999,
StartTime = SCUL.input$TreatmentBeginsAt,
EndTime = nrow(Results.y.StandardizedDiff)
)
PValue(
CohensD = .25,
StartTime = SCUL.input$TreatmentBeginsAt,
EndTime = nrow(Results.y.StandardizedDiff)
)
data_for_traditional_scm <- pivot_longer(data = cigarette_sales,
cols = starts_with(c("cigsale_", "retprice_")),
names_to = c("variable", "fips"),
names_sep = "_",
names_prefix = "X",
values_to = "value",
values_drop_na = TRUE
)
data_for_traditional_scm <- pivot_wider(data = data_for_traditional_scm,
names_from = variable,
values_from = value)
data_for_traditional_scm$fips <- as.numeric(data_for_traditional_scm$fips)
## While synth() can be used to construct synthetic control groups
## directly, by providing the X1, X0, Z1, and Z0 matrices, we strongly
## recommend to first run dataprep() to extract these matrices
## and pass them to synth() as a single object
## The usual sequence of commands is:
## 1. dataprep() for matrix-extraction
## 2. synth() for the construction of the synthetic control group
## 3. synth.tab(), gaps.plot(), and path.plot() to summarize the results
## Below we provide two examples
## First Example: Toy panel dataset
# load data
data(synth.data)
# create matrices from panel data that provide inputs for synth()
data_for_traditional_scm$idno = as.numeric(as.factor(data_for_traditional_scm$fips))  # create numeric country id required for synth()
data_for_traditional_scm <- as.data.frame(data_for_traditional_scm)
dataprep.out<-
dataprep(
foo = data_for_traditional_scm,
predictors = c("retprice"),
predictors.op = "mean",
dependent = "cigsale",
unit.variable = "idno",
time.variable = "year",
special.predictors = list(
list("cigsale", 1970, "mean"),
list("cigsale", 1980, "mean"),
list("cigsale", 1985, "mean")
),
treatment.identifier = unique(data_for_traditional_scm$idno[data_for_traditional_scm$fips==6]),
controls.identifier = unique(data_for_traditional_scm$idno[data_for_traditional_scm$fips!=6]),
time.predictors.prior = c(1970:1987),
time.optimize.ssr = c(1970:1987),
time.plot = 1970:1997
)
## run the synth command to identify the weights
## that create the best possible synthetic
## control unit for the treated.
synth.out <- synth(dataprep.out)
## there are two ways to summarize the results
## we can either access the output from synth.out directly
#round(synth.out$solution.w,2)
# contains the unit weights or
#synth.out$solution.v
## contains the predictor weights.
## the output from synth opt
## can be flexibly combined with
## the output from dataprep to
## compute other quantities of interest
## for example, the period by period
## discrepancies between the
## treated unit and its synthetic control unit
## can be computed by typing
gaps<- dataprep.out$Y1plot-(
dataprep.out$Y0plot%*%synth.out$solution.w
)
StandardizedDiff$traditional_scm <- abs(dataprep.out$Y1plot-(
dataprep.out$Y0plot%*%synth.out$solution.w
))/PreTreatmentSD
# Show Cohen's D for each of these
CohensD <- data.frame(colMeans(StandardizedDiff[1:(TreatmentBeginsAt-1),]))
# Calculate treatment effect for each of these
TreatmentEffect <- data.frame(colMeans(StandardizedDiff[TreatmentBeginsAt:nrow(StandardizedDiff),])*PreTreatmentSD)
## also there are three convenience functions to summarize results.
## to get summary tables for all information
## (V and W weights plus balance btw.
## treated and synthetic control) use the
## synth.tab() command
#ynth.tables <- synth.tab(
#  dataprep.res = dataprep.out,
#  synth.res = synth.out)
#print(synth.tables)
## to get summary plots for outcome trajectories
## of the treated and the synthetic control unit use the
## path.plot() and the gaps.plot() commands
## plot in levels (treated and synthetic)
#path.plot(dataprep.res = dataprep.out,synth.res = synth.out)
## plot the gaps (treated - synthetic)
#gaps.plot(dataprep.res = dataprep.out,synth.res = synth.out)
StandardizedDiff<-cbind(StandardizedDiff,SCUL.input$time)
colnames(StandardizedDiff)[7] <- "time"
# create smoke plot
difference_plot <- ggplot() +
theme_classic() +
geom_line(data = StandardizedDiff, aes(x = time, y = -scul.cv), alpha = 1, size = 2., color = "black") +
geom_line(data = StandardizedDiff, aes(x = time, y = -scul.cv), alpha = 1, size = 1.75, color = "#4dac26") +
geom_line(data = StandardizedDiff, aes(x = time, y = -traditional_scm), alpha = 1, size = 2., color = "black") +
geom_line(data = StandardizedDiff, aes(x = time, y = -traditional_scm), alpha = 1, size = 1.75, color = "orange", linetype = "dashed") +
geom_vline(
xintercept = SCUL.input$time[TreatmentBeginsAt,1],
linetype = "dashed",
size = 1,
color = "grey37"
) +
labs(
title = "Difference between actual cigarette sales and synthetic predictions\n from SCUL (green-solid)\n and a traditional synthetic control method (orange-dashed)",
x = "Time",
y = "Difference between actual data and predictions\n in pre-treatment standard deviations for each product"
) +
theme(
axis.text = element_text(size = 18),
axis.title.y = element_text(size = 12),
axis.title.x = element_text(size = 18),
title = element_text(size = 12)
)
# Save graph
difference_plotPath <- paste0(SCUL.input$OutputFilePath,"difference_plot.png")
ggsave(difference_plotPath,
plot = difference_plot,
width = 8,
height = 5,
dpi = 300,
units = "in")
# Display graph
difference_plot
table_for_hux_scm <- cbind(
(CohensD),
(TreatmentEffect)
)
table_for_hux_scm <- table_for_hux_scm[-(2:5),]
names(table_for_hux_scm) <- c("CohensD", "ATE")
table_for_hux_scm$name <- c("Cross-validation for determining penalty", " ")
table_for_hux_scm$value <- c(round(SCUL.output$CrossValidatedLambda, digits = 2), "NA")
table_for_hux_scm <- table_for_hux_scm[c(3, 4, 1,2)]
kable(table_for_hux_scm, col.names = c("Method","Penalty parameter", "Cohens D (pre-period fit)", "ATE estimate"), digits = 3, row.names = FALSE) %>%
kable_styling(bootstrap_options = "striped", full_width = F) %>%
column_spec(1, width = "5cm") %>%
column_spec(2:4, width = "2cm")  %>%
pack_rows("SCUL procedure using:", 1, 1) %>%
pack_rows("Traditional SCM method", 2, 2)
# Make the exact coefficients are stored as
coef.exact<-as.matrix(synth.out$solution.w)
# Add an intercept variable (always takes the value of 1) to the donor pool
# Label the first column
#colnames(x.DonorPoolWithIntercept) <- c("Intercept")
# Multiply the coefficients by the value in at each time period
ContributionToPrediction <- sweep(t(dataprep.out$Y0plot),MARGIN=1,FUN="*",STATS=coef.exact)
ContributionToPrediction <- t(ContributionToPrediction)
# Determine sign of coefficient
SignOfContribution <- ContributionToPrediction
SignOfContribution[SignOfContribution>0] <-  1
SignOfContribution[SignOfContribution<0] <- 2 #This is in this numeric order on purpose. When there are only positive weights the graphic defaults to showing them in the "first" category. So we want that to be the lower number here.
SignOfContribution<-SignOfContribution[ , !apply(SignOfContribution==0,2,all)]
# Take the absolute value of everything since we are concerned with contribution
ContributionToPrediction <- abs(ContributionToPrediction)
# Without the intercept, percentage of contribution each variable makes to the prediction
ShareOfPrediction <-sweep(ContributionToPrediction,MARGIN=1,FUN="/",STATS=rowSums(ContributionToPrediction))
#rowSums(ShareOfPrediction)
## Remove zero contributions
#Value_of_prediction<-value_of_prediction[ , !apply(share_of_prediction==0,2,all)]
ShareOfPrediction<-ShareOfPrediction[ , !apply(ShareOfPrediction==0,2,all)]
coef.exact<-coef.exact[apply(coef.exact,1,function(x) all(abs(x)>0))]
## Show the top five items in the time treatment began without intercept
# Note: Percents are [0-1]
#head(sort(ShareOfPrediction[SCUL.input$TreatmentBeginsAt,], decreasing=TRUE))
## Create a data frame with the share of prediction in the time of treatment and the last time observed.
ShareOfPredictionForPlot<-data.frame(ShareOfPrediction[TreatmentBeginsAt,],ShareOfPrediction[length(SCUL.output$y.actual),],SignOfContribution[TreatmentBeginsAt,],coef.exact)
#create a variable from the row names
ShareOfPredictionForPlot$names=row.names(ShareOfPredictionForPlot)
#label the columns
colnames(ShareOfPredictionForPlot) <- c("share.1","share.2","sign", "coef", "RowNames")
# sort by the contribution in the first time
ShareOfPredictionForPlot<-ShareOfPredictionForPlot[order(-abs(ShareOfPredictionForPlot$share.1)),]
# Create a variable that stores this order
for (i in 1:nrow(ShareOfPredictionForPlot)) {
ShareOfPredictionForPlot$order[i]<- nrow(ShareOfPredictionForPlot)-i+1
}
ShareOfPredictionForPlot$order<-as.numeric(ShareOfPredictionForPlot$order)
# Keep only the parts we need for the table
ShareOfPredictionForTable<-ShareOfPredictionForPlot[,1:4]
ShareOfPredictionForTable<-ShareOfPredictionForTable[,-3]
ShareOfPredictionForTable[,1]<-round(ShareOfPredictionForTable[,1],digits=4)
ShareOfPredictionForTable[,2]<-round(ShareOfPredictionForTable[,2],digits=4)
ShareOfPredictionForTable[,3]<-round(ShareOfPredictionForTable[,3],digits=4)
colnames(ShareOfPredictionForTable) <- c("Share for\n First Prediction" ,"Share for Most\n Recent Prediction","Coefficient")
# Make it so the coef is green/red for positive/negative
sign_formatter <- formatter("span",
style = x ~ style(color = ifelse(x > 0, "green",
ifelse(x < 0, "red", "black"))))
# Plot the
SharesInTable<-formattable(ShareOfPredictionForTable,align =c("r","r","r"), list(
area(col = c("Share for\n First Prediction", "Share for Most\n Recent Prediction")) ~ normalize_bar(color = "#3399FF", 0.2),
"Coefficient" = sign_formatter
))
SharesInTable
# Combine the two plots for the readme
PlotForReadMe <- plot_grid(
smoke_plot, combined_plot,
ncol = 2, rel_widths = c(1, .45))
ReadMePlotPath <- paste0(SCUL.input$OutputFilePath,"ReadMeFigure.png")
ggsave(ReadMePlotPath,
plot = PlotForReadMe,
width = 12,
height = 6,
dpi = 300,
units = "in")
ggsave("vignette_output/time_series_convex_hull.png",
plot = PlotForReadMe,
dpi = 300,
width = 12,
height = 6,
units = "in")
list = ls()
rm(list=ls()[! ls() %in% c("PlotForReadMe")])
pkgdown::build_site()
devtools::document()
devtools::build()
devtools::install()
pkgdown::build_site()
devtools::document()
devtools::build()
devtools::install()
pkgdown::build_site()
devtools::document()
devtools::build()
devtools::install()
pkgdown::build_site()
devtools::document()
devtools::build()
devtools::install()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
devtools::document()
devtools::build()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
use_this::use_github_actions()
usethis::use_github_actions()
library(usethis)
use_mit_license("Alex Hollingsworth")
use_news_md()
pkgdown::build_site()
use_news_md()
pkgdown::build_site()
if (!require("devtools")) install.packages("devtools")
pkgdown::build_site()
pkgdown::build_site()
devtools::document()
devtools::build()
devtools::install()
pkgdown::build_site()
devtools::document()
devtools::build()
devtools::install()
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
pkgdown::build_site()
install.packages("pkgdown")
pkgdown::build_site()
